{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run src/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm \n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_train_df = data['adult']['train']['engineered']\n",
    "adult_train_target = data['adult']['train']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_training_set(X_train, y_train, n_pcnt):\n",
    "    n = X_train.shape[0]*n_pcnt//100\n",
    "    return n, X_train[:n], y_train[:n]\n",
    "\n",
    "def time_function_call(function_call):\n",
    "    start = time()\n",
    "    result = function_call\n",
    "    execution_time = time() - start\n",
    "    return result, execution_time\n",
    "\n",
    "def run_model(model, model_name, n_pcnt, data, labels):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, stratify=labels)\n",
    "\n",
    "    \n",
    "    n, X_samp, y_samp = sample_training_set(X_train, y_train, n_pcnt)\n",
    "    \n",
    "    _, fit_time = time_function_call(\n",
    "        model.fit(X_samp, y_samp))\n",
    "    \n",
    "    train_pred, train_pred_time = time_function_call(\n",
    "        model.predict(X_samp))\n",
    "    \n",
    "    test_pred, test_pred_time = time_function_call(\n",
    "        model.predict(X_test))    \n",
    "    \n",
    "    return {\n",
    "            'model' : model,\n",
    "            'model_name' : model_name,\n",
    "            'n_pcnt' : n_pcnt,\n",
    "            'n' : n,\n",
    "            'f1_train_score' : f1_score(y_samp, train_pred),\n",
    "            'f1_test_score' : f1_score(y_test, test_pred),\n",
    "            'accuracy_train_score' : model.score(X_samp, y_samp),\n",
    "            'accuracy_test_score' : model.score(X_test, y_test),\n",
    "            'fit_time' : fit_time,\n",
    "            'train_pred_time' : train_pred_time,\n",
    "            'test_pred_time' : test_pred_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Ranking - by Single Feature F$_1$ Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for feature in adult_train_df.columns:\n",
    "    results = run_model(LogisticRegression(), 'variable ranking', 50, adult_train_df[[feature]], adult_train_target)\n",
    "    test_score = results['f1_test_score']\n",
    "    if test_score > 0:\n",
    "        test_scores.append({'feature': feature, 'score' : test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(test_scores).sort_values('score', ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performant_features = list(results.feature.values)\n",
    "performant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_test = []\n",
    "test_results = {}\n",
    "for feature in performant_features:\n",
    "    features_to_test.append(feature)\n",
    "    test_results[feature] = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                      adult_train_df[features_to_test],\n",
    "                                      adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(test_results).T.sort_values('n')\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(features_to_test)), test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(features_to_test)), test_results.f1_train_score, label='train performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable-Ranking - By Regression Coefficient in Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_model(LogisticRegression(), 'logit', 100,\n",
    "                    adult_train_df,\n",
    "                    adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = results['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logistic_regression_model.coef_\n",
    "features = adult_train_df.columns\n",
    "coefficients = pd.Series(coefficients.T.ravel(), index=features)\n",
    "coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_coefs = np.abs(coefficients).sort_values(ascending=False)\n",
    "sorted_coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performant_features = list(list(sorted_coefs.head(20).index))\n",
    "performant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_test = []\n",
    "test_results = {}\n",
    "for feature in performant_features:\n",
    "    print(adult_train_df[features_to_test].shape)\n",
    "    features_to_test.append(feature)\n",
    "    test_results[feature] = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                      adult_train_df[features_to_test],\n",
    "                                      adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(test_results).T.sort_values('n')\n",
    "\n",
    "plt.plot(range(len(features_to_test)), test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(features_to_test)), test_results.f1_train_score, label='train performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_test = ['age', 'capital-gain','capital-loss','hours-per-week']\n",
    "test_results = {}\n",
    "for feature in performant_features:\n",
    "    print(adult_train_df[features_to_test].shape)\n",
    "    features_to_test.append(feature)\n",
    "    test_results[feature] = run_model(LogisticRegression(), 'logit', 100,\n",
    "                                      adult_train_df[features_to_test],\n",
    "                                      adult_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(test_results).T.sort_values('n')\n",
    "\n",
    "plt.plot(range(len(features_to_test)-4), test_results.f1_test_score, label='test performance')\n",
    "plt.plot(range(len(features_to_test)-4), test_results.f1_train_score, label='train performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
